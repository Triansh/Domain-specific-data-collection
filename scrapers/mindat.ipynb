{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458108ef-6051-4283-8593-0045b2ef7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0923f251-caf7-413b-a842-6b674c1fb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Global variables to store mineral data.\n",
    "\"\"\"\n",
    "all_mineral_dict = {}\n",
    "min_dict = {}\n",
    "skipped = []\n",
    "collapse_finder = re.compile(r\"collapse[0-9]+\")\n",
    "FILE_NUM = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68a232b-4196-4160-98bf-a15a4d3f572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_key_to_dict(key, value):\n",
    "    \"\"\"\n",
    "    When scraping, each key ends with a colon, so we first find the\n",
    "    colon from the end and take the string till it.\n",
    "    The key may have a value before so we push the new as well as old value in a list.\n",
    "    If key is not present, then we simply add its value in form of string.\n",
    "\n",
    "    :param key: The key to add in dictionary\n",
    "    :param value: The value associated with the key\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global min_dict\n",
    "    ind = key.rfind(':')\n",
    "    if ind == -1: return\n",
    "    key = key[:ind]\n",
    "\n",
    "    if key not in min_dict:\n",
    "        min_dict[key] = value\n",
    "    elif isinstance(min_dict[key], list):\n",
    "        min_dict[key].append(value)\n",
    "    else:\n",
    "        min_dict[key] = [min_dict[key], value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8400dbe5-acab-45e9-adf5-f33c4701f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intro_data(div):\n",
    "    \"\"\"\n",
    "    There is a section in mindat which corresponds to introduction of mineral.\n",
    "    Here we find that div and retrieve its attributes.\n",
    "    :param div:  The div where introdata class div has to be located.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        intro = div.find(\"div\", {\"id\": \"introdata\"})\n",
    "        for x in intro.find_all(\"div\", recursive=False):\n",
    "            try:\n",
    "                key = x.span.text\n",
    "                value = x.div.text\n",
    "                add_key_to_dict(key, value)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c9e37b0-e7be-4323-8b33-e161dfb84bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_attributes(divs):\n",
    "    \"\"\"\n",
    "    Apart from introdata, we retrieve attributes from div that have class\n",
    "    of mindatarow. Some preprocessing is also required sometimes to get quality data.\n",
    "\n",
    "    :param divs: A list of divs to search for attributes\n",
    "    :return:  None\n",
    "    \"\"\"\n",
    "    for div in divs:\n",
    "        try:\n",
    "            rows = div.find_all('div', {'class': 'mindatarow'})\n",
    "            for row in rows:\n",
    "                text = row.find_all('div', recursive=False)\n",
    "                if len(text) != 2: continue\n",
    "                try:\n",
    "                    key = text[0].text\n",
    "                    if lis := text[1].find_all('li', recursive=False):\n",
    "                        value = '\\n'.join([x.text for x in lis])\n",
    "                    else:\n",
    "                        value = text[1].text\n",
    "                    add_key_to_dict(key, value)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        except Exception as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "919ff49d-091e-44c7-80ae-888826281d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_data():\n",
    "    with open(f'../data/mindat/collected_data-{FILE_NUM}.json', 'w') as f:\n",
    "        json.dump(all_mineral_dict, f)\n",
    "    with open(f'../data/mindat/skipped_data-{FILE_NUM}.txt', 'w') as f:\n",
    "        f.write('\\n'.join(str(x) for x in skipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c8217d8-ec50-4e26-89f1-1a1546fe5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_parsing(index, html_text):\n",
    "    \"\"\"\n",
    "\n",
    "    Parses the html text to obtain all the attributes by first moving down\n",
    "    the html tree and then calling the above mentioned functions. At last\n",
    "    dumps the data in output JSON file.\n",
    "\n",
    "    :param index: Mindat mineral ID to process\n",
    "    :param html_text: parses the html text using BeautifulSoup\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global min_dict\n",
    "    global skipped\n",
    "    min_dict = {}\n",
    "\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    try:\n",
    "        container = soup.body.find(\"div\", {\"id\": \"mainwrap\"}).find(\"div\",\n",
    "                                                                   {\"class\": \"centerer\"}).find(\n",
    "            \"div\", {\"class\": \"mindatadiv\"}).find(\"div\", {\"class\": \"fpbox990nl\"})\n",
    "        mineral_name = container.find(\"h1\", {\"class\": \"mineralheading\"}).text\n",
    "        print(mineral_name)\n",
    "        divs = container.find_all(\"div\", {\"id\": collapse_finder})\n",
    "        get_intro_data(divs[0])\n",
    "        get_other_attributes(divs)\n",
    "\n",
    "        all_mineral_dict[mineral_name] = {}\n",
    "        for k, val in min_dict.items():\n",
    "            if isinstance(val, list):\n",
    "                val = list(set(val))\n",
    "                if len(val) == 1:\n",
    "                    val = val[0]\n",
    "            all_mineral_dict[mineral_name][k] = val\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Extraction failed\")\n",
    "        skipped.append(num)\n",
    "    dump_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a598afe-2f1a-4e4b-9dcf-60b2d71e1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = []\n",
    "\n",
    "\n",
    "def scrape(html_text):\n",
    "    \"\"\"\n",
    "    This is repsonsible to extract out the mineral IDS of core minerals in mindat that\n",
    "    are present in A-Z index from the <a> tag\n",
    "\n",
    "    :param html_text: html text for index\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global min_dict\n",
    "    global skipped\n",
    "    min_dict = {}\n",
    "\n",
    "    soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "    try:\n",
    "        container = soup.body.find(\"div\", {\"id\": \"mainwrap\"}).find(\"div\",\n",
    "                                                                   {\"class\": \"centerer\"}).find(\n",
    "            \"div\", {\"class\": \"fpbox720p\"}).find(\"div\", {\"class\": \"newminsearchresults\"})\n",
    "        divs = container.find_all(\"a\", href=True)\n",
    "        for a in divs:\n",
    "            mins.append(a['href'][4:-5])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Extraction failed\")\n",
    "        skipped.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842cae7d-d1b5-43dc-b9fd-ba1f1c288993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number A parsed.\n",
      "\n",
      "Page number B parsed.\n",
      "\n",
      "Page number C parsed.\n",
      "\n",
      "Page number D parsed.\n",
      "\n",
      "Page number E parsed.\n",
      "\n",
      "Page number F parsed.\n",
      "\n",
      "Page number G parsed.\n",
      "\n",
      "Page number H parsed.\n",
      "\n",
      "Page number I parsed.\n",
      "\n",
      "Page number J parsed.\n",
      "\n",
      "Page number K parsed.\n",
      "\n",
      "Page number L parsed.\n",
      "\n",
      "Page number M parsed.\n",
      "\n",
      "Page number N parsed.\n",
      "\n",
      "Page number O parsed.\n",
      "\n",
      "Page number P parsed.\n",
      "\n",
      "Page number Q parsed.\n",
      "\n",
      "Page number R parsed.\n",
      "\n",
      "Page number S parsed.\n",
      "\n",
      "Page number T parsed.\n",
      "\n",
      "Page number U parsed.\n",
      "\n",
      "Page number V parsed.\n",
      "\n",
      "Page number W parsed.\n",
      "\n",
      "Page number X parsed.\n",
      "\n",
      "Page number Y parsed.\n",
      "\n",
      "Page number Z parsed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loop to get all mineral IDs\n",
    "\"\"\"\n",
    "for c in string.ascii_uppercase:\n",
    "    base_url = f\"https://www.mindat.org/index-{c}.html\"\n",
    "    #     url = f\"{base_url}/min-{num}.html\"\n",
    "    html_text = requests.get(base_url).text\n",
    "    scrape(html_text)\n",
    "    print(f\"Page number {c} parsed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182a33c3-e43f-406b-87e0-ef3cacf1bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5747"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = [x for x in mins]\n",
    "len(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c7228c8-7631-46e0-a13d-ae3eb6610876",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/mindat/all-mins.txt', 'w') as f:\n",
    "    f.write('\\n'.join(ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66d8b7-150a-4523-a316-66fafc5f81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loop to query data of all minerals.\n",
    "\"\"\"\n",
    "base_url = \"https://www.mindat.org\"\n",
    "\n",
    "with open('../data/mindat/skipped_data-50.txt') as f:\n",
    "    nums = sorted(set([int(x.strip()) for x in f]))\n",
    "\n",
    "for num in nums:\n",
    "    url = f\"{base_url}/min-{num}.html\"\n",
    "    html_text = requests.get(url).text\n",
    "    start_parsing(num, html_text)\n",
    "    print(f\"Page number {num} parsed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65e4aac4-4ba8-45ed-b81c-d849ed92815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = \"https://www.mindat.org\"\n",
    "\n",
    "# for num in range(7000, 10000):\n",
    "#     url = f\"{base_url}/min-{num}.html\"\n",
    "#     html_text = requests.get(url).text\n",
    "#     start_parsing(num, html_text)\n",
    "#     print(f\"Page number {num} parsed.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b4e26-acf9-46a9-a142-e42aea415528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2759e852014336ba67366e8bd1c913103852bba2c1225da5ad8b1248589b036"
  },
  "kernelspec": {
   "display_name": "jupy-lab-kernel",
   "language": "python",
   "name": "jupy-lab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
